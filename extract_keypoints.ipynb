{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusuke-satani/swing_classification/blob/main/extract_keypoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bd3efc-8622-4368-a0c0-12916549c093",
      "metadata": {
        "id": "05bd3efc-8622-4368-a0c0-12916549c093"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdf97f34-b5e9-4bde-8439-4fe79b95e509",
      "metadata": {
        "id": "bdf97f34-b5e9-4bde-8439-4fe79b95e509"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8n-pose.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf9639c-d106-4ab0-b683-9f414ca254a9",
      "metadata": {
        "scrolled": true,
        "id": "aaf9639c-d106-4ab0-b683-9f414ca254a9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def extract_keypoints(frames):\n",
        "    all_keypoints = []\n",
        "    device = torch.device('mps')\n",
        "    for frame in frames:\n",
        "        frame = torch.tensor(frame, dtype=torch.float32).to(device)\n",
        "        results = model(frame)\n",
        "\n",
        "        if len(results) > 0 and len(results[0].keypoints) > 0:\n",
        "            keypoints_list = results[0].keypoints\n",
        "            bboxes = results[0].boxes  # list bounding boxes\n",
        "\n",
        "            if bboxes is not None and len(bboxes) > 0:\n",
        "                # calculate the area of bounding boxes\n",
        "                try:\n",
        "                    xyxy = bboxes.xyxy.cpu().numpy()  # Get bounding box coordinates\n",
        "                    areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in xyxy]\n",
        "                except IndexError as e:\n",
        "                    print(f\"Error calculating areas: {e}\")\n",
        "                    print(f\"Bounding boxes: {bboxes}\")\n",
        "                    continue\n",
        "\n",
        "                # Get the index of the largest bounding box\n",
        "                max_area_index = np.argmax(areas)\n",
        "\n",
        "                # Get the keypoint corresponding to the largest bounding box\n",
        "                keypoints = keypoints_list[max_area_index].xy[0].cpu().numpy()\n",
        "\n",
        "                all_keypoints.append(keypoints)\n",
        "            else:\n",
        "                print(f\"Warning: No bounding boxes found in frame.\")\n",
        "        else:\n",
        "            print(f\"Warning: No keypoints found in frame.\")\n",
        "    return all_keypoints\n",
        "\n",
        "\n",
        "def normalize_keypoints(keypoints):\n",
        "    hip_index = 11  #  index of left hip\n",
        "    shoulder_index = 5  # index of shoulder\n",
        "\n",
        "    normalized_keypoints = []\n",
        "    for frame_keypoints in keypoints:\n",
        "        if len(frame_keypoints) > max(hip_index, shoulder_index):\n",
        "            hip_point = frame_keypoints[hip_index]\n",
        "            shoulder_point = frame_keypoints[shoulder_index]\n",
        "\n",
        "            # Calculate the point of the hip as the origin (0,0) and other points as relative positions to make the model robust\n",
        "            relative_points = frame_keypoints - hip_point\n",
        "            scale_factor = np.linalg.norm(shoulder_point - hip_point)\n",
        "            if scale_factor != 0:\n",
        "                relative_points /= scale_factor\n",
        "\n",
        "            normalized_keypoints.append(relative_points)\n",
        "        else:\n",
        "            print(f\"Warning: Frame with insufficient keypoints detected. Skipping this frame.\")\n",
        "\n",
        "    return np.array(normalized_keypoints)\n",
        "\n",
        "def process_folder(folder_path, label):\n",
        "    print(f\"Processing folder: {folder_path}\")\n",
        "    video_data = []\n",
        "    for video_file in os.listdir(folder_path):\n",
        "        if video_file.endswith(('.mp4', '.avi', '.mov')):\n",
        "            video_path = os.path.join(folder_path, video_file)\n",
        "            frames = process_video(video_path)\n",
        "            keypoints = extract_keypoints(frames)\n",
        "            if len(keypoints) > 0:\n",
        "                normalized_keypoints = normalize_keypoints(keypoints)\n",
        "                if len(normalized_keypoints) > 0:\n",
        "                    video_data.append((normalized_keypoints, label))\n",
        "                else:\n",
        "                    print(f\"Warning: No valid keypoints found in video {video_file}\")\n",
        "            else:\n",
        "                print(f\"Warning: No keypoints detected in video {video_file}\")\n",
        "    return video_data\n",
        "    print(f\"Number of videos processed: {len(video_data)}\")\n",
        "\n",
        "shot_types = ['forehand_stroke','forehand_slice','forehand_volley', 'backhand_stroke', 'backhand_volley', 'backhand_slice']\n",
        "all_data = []\n",
        "for label, shot_type in enumerate(shot_types):\n",
        "    folder_path = f'file_path{shot_type}'\n",
        "    all_data.extend(process_folder(folder_path, label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92faaa2c-59fc-4046-a3dc-c840027b1901",
      "metadata": {
        "id": "92faaa2c-59fc-4046-a3dc-c840027b1901",
        "outputId": "6b1c2c17-80fb-41f5-8866-e88fa0f2c483"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"import numpy as np\\n# Convert to numpy array\\nall_data_array = np.array(all_data, dtype=object)\\n# Save to .npy file\\nnp.save('all_data.npy', all_data_array)\""
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Convert to numpy array\n",
        "all_data_array = np.array(all_data, dtype=object)\n",
        "# Save to .npy file\n",
        "np.save('swing_class.npy', all_data_array)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}