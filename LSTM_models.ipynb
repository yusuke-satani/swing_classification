{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yusuke-satani/swing_classification/blob/main/LSTM_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05bd3efc-8622-4368-a0c0-12916549c093",
      "metadata": {
        "id": "05bd3efc-8622-4368-a0c0-12916549c093",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qkfomhpzIXs5"
      },
      "id": "qkfomhpzIXs5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04e037d6-7abd-4646-bb7e-429754216e95",
      "metadata": {
        "id": "04e037d6-7abd-4646-bb7e-429754216e95"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "all_data = np.load('/content/drive/MyDrive/all_data.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335839cf-fa3d-4fcb-b693-fa2bb529abea",
      "metadata": {
        "id": "335839cf-fa3d-4fcb-b693-fa2bb529abea"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(sequences, max_length):\n",
        "    # Align sequence lengths\n",
        "    return [seq[:max_length] if len(seq) > max_length else np.pad(seq, ((0, max_length - len(seq)), (0, 0), (0, 0)), 'constant') for seq in sequences]\n",
        "\n",
        "X = [data[0] for data in all_data]\n",
        "y = [data[1] for data in all_data]\n",
        "\n",
        "# Align sequence lengths\n",
        "X_padded = pad_sequences(X, 100)\n",
        "\n",
        "X_array = np.array(X_padded)\n",
        "y_array = np.array(y)\n",
        "shot_types = ['forehand_stroke','forehand_volley','forehand_slice','backhand_stroke','backhand_volley','backhand_slice']\n",
        "y_onehot = np.eye(len(shot_types))[y_array]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c57d974-909f-4cae-a548-173e44fb2cae",
      "metadata": {
        "id": "2c57d974-909f-4cae-a548-173e44fb2cae"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, AdditiveAttention, Concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "def create_lstm_attention_model(sequence_length, num_keypoints, num_coords, num_classes):\n",
        "    inputs = Input(shape=(sequence_length, num_keypoints * num_coords))\n",
        "    x = LSTM(128, return_sequences=True)(inputs)\n",
        "    attention = AdditiveAttention()([x, x])\n",
        "    x = Concatenate()([x, attention])\n",
        "    x = LSTM(64, return_sequences=True)(x)\n",
        "    attention = AdditiveAttention()([x, x])\n",
        "    x = Concatenate()([x, attention])\n",
        "    x = LSTM(32)(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_array, y_onehot, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)\n",
        "\n",
        "train_generator = DataGenerator(X_train, y_train, batch_size=16)\n",
        "val_generator = DataGenerator(X_val, y_val, batch_size=16)\n",
        "test_generator = DataGenerator(X_test, y_test, batch_size=16)\n",
        "\n",
        "sequence_length = X_train.shape[1]\n",
        "num_keypoints = 17\n",
        "num_coords = 2\n",
        "num_classes = 6\n",
        "model = create_lstm_attention_model(sequence_length, num_keypoints, num_coords, num_classes)\n",
        "\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(np.argmax(y_train, axis=1)), y=np.argmax(y_train, axis=1))\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=100,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weight_dict\n",
        ")\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d22da0e1-3977-4aa5-bcf8-062349740cda",
      "metadata": {
        "id": "d22da0e1-3977-4aa5-bcf8-062349740cda"
      },
      "outputs": [],
      "source": [
        "model.save('swing_class.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e850997-b4f9-452b-892c-4c69f63232d7",
      "metadata": {
        "id": "6e850997-b4f9-452b-892c-4c69f63232d7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('/content/drive/MyDrive/swing_class.h5')\n",
        "\n",
        "predictions = loaded_model.predict(test_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator\n",
        "np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "id": "e5dT6YE1YPz5"
      },
      "id": "e5dT6YE1YPz5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}