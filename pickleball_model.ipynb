{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DIdsUlyLxJy0",
        "outputId": "b5afdd07-b1f7-49fe-db0c-15718f9480de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.70-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.70-py3-none-any.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.70 ultralytics-thop-2.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import deque\n",
        "from ultralytics import YOLO\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NBW2vyTPeJSt",
        "outputId": "099e89f2-d667-4116-9586-3ac2c5a20841",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n-pose.pt')\n",
        "swing_detect_model = load_model('/content/drive/MyDrive/swing_detect.h5')\n",
        "shot_class_model =load_model('/content/drive/MyDrive/swing_class_100frames.h5')"
      ],
      "metadata": {
        "id": "SNjwa2ROfy9A",
        "outputId": "eddff80f-d207-4e62-aa59-2f30e4c93821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l-pose.pt to 'yolov8l-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 85.3M/85.3M [00:00<00:00, 128MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swing_detect_class=['swing_begin','swing_middle','swing_end']\n",
        "shot_class = ['forehand_stroke', 'forehand_slice', 'forehand_volley', 'backhand_stroke', 'backhand_volley', 'backhand_slice']"
      ],
      "metadata": {
        "id": "CZ9rQ1lAeT4s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_frame(frame):\n",
        "    # Resize the frame to a specific size (e.g., 640x640)\n",
        "    frame = cv2.resize(frame, (640, 640))\n",
        "    # Convert BGR to RGB\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    frame = frame.astype(np.float32) / 255.0\n",
        "    # Add batch dimension\n",
        "    frame = np.expand_dims(frame, axis=0)\n",
        "    # Permute dimensions to match the model's expected input (BCHW)\n",
        "    frame = np.transpose(frame, (0, 3, 1, 2))\n",
        "    return frame\n",
        "\n",
        "def extract_keypoints(frames):\n",
        "    all_keypoints = []\n",
        "    device = torch.device('cuda')\n",
        "    for frame in frames:\n",
        "        frame = preprocess_frame(frame)\n",
        "        frame = torch.tensor(frame, dtype=torch.float32).to(device)\n",
        "        results = model(frame,verbose=False)\n",
        "        if len(results) > 0 and len(results[0].keypoints) > 0:\n",
        "            keypoints_list = results[0].keypoints\n",
        "            bboxes = results[0].boxes\n",
        "            if bboxes is not None and len(bboxes) > 0:\n",
        "                try:\n",
        "                    xyxy = bboxes.xyxy.cpu().numpy()  # get xyxy cordinates to find the closest peron to the camera.\n",
        "                    areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in xyxy]\n",
        "                except IndexError as e:\n",
        "                    print(f\"Error calculating areas: {e}\")\n",
        "                    print(f\"Bounding boxes: {bboxes}\")\n",
        "                    continue\n",
        "\n",
        "                max_area_index = np.argmax(areas)   # get the index that contain the biggest bbox\n",
        "                keypoints = keypoints_list[max_area_index].xy[0].cpu().numpy()  #get the keypoints from the biggest bbox\n",
        "                all_keypoints.append(keypoints)\n",
        "            else:\n",
        "                print(f\"Warning: No bounding boxes found in frame.\")\n",
        "        else:\n",
        "            print(f\"Warning: No keypoints found in frame.\")\n",
        "\n",
        "    return all_keypoints\n",
        "\n",
        "\n",
        "def normalize_keypoints(keypoints):\n",
        "    hip_index = 11  #  index of left hip\n",
        "    shoulder_index = 5  # index of shoulder\n",
        "\n",
        "    normalized_keypoints = []\n",
        "    for frame_keypoints in keypoints:\n",
        "        if len(frame_keypoints) > max(hip_index, shoulder_index):\n",
        "            hip_point = frame_keypoints[hip_index]\n",
        "            shoulder_point = frame_keypoints[shoulder_index]\n",
        "            #  set hip point as (0,0) cordinates, set distance from hip to shoulder as 1 in every input.\n",
        "            relative_points = frame_keypoints - hip_point\n",
        "            # scaling\n",
        "            scale_factor = np.linalg.norm(shoulder_point - hip_point)\n",
        "            if scale_factor != 0:\n",
        "                relative_points /= scale_factor\n",
        "            normalized_keypoints.append(relative_points)\n",
        "        else:\n",
        "            print(f\"Warning: Frame with insufficient keypoints detected. Skipping this frame.\")\n",
        "\n",
        "    return np.array(normalized_keypoints)\n",
        "\n"
      ],
      "metadata": {
        "id": "IVazGlaIjTuS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, batch_size):\n",
        "        self.x = x_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x\n",
        "\n"
      ],
      "metadata": {
        "id": "awo_2N5_jTrk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/test_30s.mp4\""
      ],
      "metadata": {
        "id": "P5U-X0s4jTFT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_buffer = deque(maxlen=25)\n",
        "swing_frames = deque(maxlen=100)\n",
        "is_recording_swing = False\n",
        "\n",
        "\n",
        "test_pred=[]\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  frame_buffer.append(frame)\n",
        "  if len(frame_buffer) == 25:\n",
        "    if not is_recording_swing:\n",
        "      keypoints = extract_keypoints(frame_buffer)\n",
        "      if len(keypoints) > 0:\n",
        "        normalized_keypoints = normalize_keypoints(keypoints)\n",
        "        #change keypoints to the numpy\n",
        "        X_array = np.array(normalized_keypoints)\n",
        "        X_array = X_array.reshape(X_array.shape[0], X_array.shape[1], -1)\n",
        "        #print(X_array.shape)\n",
        "        X_array = X_array.reshape((1, X_array.shape[0], X_array.shape[1] * X_array.shape[2]))\n",
        "        generator = DataGenerator(X_array, batch_size=1)\n",
        "        predictions = swing_detect_model.predict(generator)\n",
        "        swing_prediction = np.argmax(predictions, axis=1)\n",
        "        test_pred.append(swing_prediction[0])\n",
        "        #print(\"swing prrediction is \"+str(swing_prediction))\n",
        "\n",
        "        for _ in range(5):\n",
        "            if frame_buffer:\n",
        "                frame_buffer.popleft()\n",
        "\n",
        "\n",
        "\n",
        "    # if is_recording_swing = True\n",
        "\n",
        "\n",
        "cap.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "-kvhb4aypevd",
        "outputId": "dc4ac655-da0c-4c9f-9953-f386a69f3939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred"
      ],
      "metadata": {
        "id": "Z958vg5Ype0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcBtHgLfpe24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNVPRF4fpe60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lCaXv7Ipe8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JA7hxXOpe9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOj94JippfBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auT9Os9ZpfEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcqpdT4Ipfgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9i9CS-_pfkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_swing_start(keypoints_sequence):\n",
        "    if keypoints_sequence is not None and len(keypoints_sequence) == 35:\n",
        "        keypoints_sequence = np.array(keypoints_sequence)\n",
        "        keypoints_sequence = np.expand_dims(keypoints_sequence, axis=0)\n",
        "        prediction = swing_start_model.predict(keypoints_sequence)\n",
        "        return prediction[0][0] > 0.5  # 閾値は適宜調整してください\n",
        "    return False\n",
        "\n",
        "def classify_swing(keypoints_sequence):\n",
        "    if keypoints_sequence is not None and len(keypoints_sequence) == 30:\n",
        "        keypoints_sequence = np.array(keypoints_sequence)\n",
        "        keypoints_sequence = np.expand_dims(keypoints_sequence, axis=0)\n",
        "        prediction = swing_classification_model.predict(keypoints_sequence)\n",
        "        return np.argmax(prediction)\n",
        "    return None\n",
        "\n",
        "# 動画ファイルの読み込み\n",
        "cap = cv2.VideoCapture('path/to/your/video.mp4')\n",
        "\n",
        "frame_buffer = deque(maxlen=35)\n",
        "swing_frames = deque(maxlen=30)\n",
        "is_recording_swing = False\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    keypoints = extract_keypoints(frame)\n",
        "    normalized_keypoints = normalize_keypoints(keypoints)\n",
        "\n",
        "    if normalized_keypoints is not None:\n",
        "        frame_buffer.append(normalized_keypoints)\n",
        "\n",
        "        if len(frame_buffer) == 35:\n",
        "            if is_swing_start(list(frame_buffer)):\n",
        "                is_recording_swing = True\n",
        "                swing_frames.clear()\n",
        "                swing_frames.extend(list(frame_buffer)[-30:])  # 最後の30フレームを使用\n",
        "\n",
        "        if is_recording_swing:\n",
        "            swing_frames.append(normalized_keypoints)\n",
        "\n",
        "            if len(swing_frames) == 30:\n",
        "                swing_class = classify_swing(list(swing_frames))\n",
        "                if swing_class is not None:\n",
        "                    label = shot_types[swing_class]\n",
        "                    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "                is_recording_swing = False\n",
        "\n",
        "    cv2.imshow('Swing Classification', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # 3フレームごとにframe_bufferの先頭を削除\n",
        "    if len(frame_buffer) == 35:\n",
        "        for _ in range(3):\n",
        "            if frame_buffer:\n",
        "                frame_buffer.popleft()\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "YRXMoOWZpfzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "for label, shot_type in enumerate(shot_types):\n",
        "    folder_path = f'/Users/yusuke.s/Documents/pickleball_videos/{shot_type}'\n",
        "    all_data.extend(process_video(folder_path, label))"
      ],
      "metadata": {
        "id": "QxDOG1wbhO_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}