{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIdsUlyLxJy0",
        "outputId": "c9c56c33-80e2-49e3-8911-66374b553708",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.70-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m41.0/41.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m801.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.70-py3-none-any.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.6/862.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.70 ultralytics-thop-2.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from collections import deque\n",
        "from ultralytics import YOLO\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NBW2vyTPeJSt",
        "outputId": "7244b1f8-93ad-478c-d2f0-c519b73d4756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n-pose.pt')\n",
        "swing_detect_model = load_model('/content/drive/MyDrive/swing_detect.h5')\n",
        "shot_class_model =load_model('/content/drive/MyDrive/swing_class_100frames.h5')"
      ],
      "metadata": {
        "id": "SNjwa2ROfy9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "swing_detect_class=['swing_begin','swing_middle','swing_end']\n",
        "shot_class = ['forehand_stroke', 'forehand_slice', 'forehand_volley', 'backhand_stroke', 'backhand_volley', 'backhand_slice']"
      ],
      "metadata": {
        "id": "CZ9rQ1lAeT4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_frame(frame):\n",
        "    # Resize the frame to a specific size (e.g., 640x640)\n",
        "    frame = cv2.resize(frame, (640, 640))\n",
        "    # Convert BGR to RGB\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    # Normalize pixel values to [0, 1]\n",
        "    frame = frame.astype(np.float32) / 255.0\n",
        "    # Add batch dimension\n",
        "    frame = np.expand_dims(frame, axis=0)\n",
        "    # Permute dimensions to match the model's expected input (BCHW)\n",
        "    frame = np.transpose(frame, (0, 3, 1, 2))\n",
        "    return frame\n",
        "\n",
        "def extract_keypoints(frames):\n",
        "    all_keypoints = []\n",
        "    device = torch.device('cpu')\n",
        "    for frame in frames:\n",
        "        frame = preprocess_frame(frame)\n",
        "        frame = torch.tensor(frame, dtype=torch.float32).to(device)\n",
        "        results = model(frame)\n",
        "        if len(results) > 0 and len(results[0].keypoints) > 0:\n",
        "            keypoints_list = results[0].keypoints\n",
        "            bboxes = results[0].boxes\n",
        "            if bboxes is not None and len(bboxes) > 0:\n",
        "                try:\n",
        "                    xyxy = bboxes.xyxy.cpu().numpy()  # get xyxy cordinates to find the closest peron to the camera.\n",
        "                    areas = [(box[2] - box[0]) * (box[3] - box[1]) for box in xyxy]\n",
        "                except IndexError as e:\n",
        "                    print(f\"Error calculating areas: {e}\")\n",
        "                    print(f\"Bounding boxes: {bboxes}\")\n",
        "                    continue\n",
        "\n",
        "                max_area_index = np.argmax(areas)   # get the index that contain the biggest bbox\n",
        "                keypoints = keypoints_list[max_area_index].xy[0].cpu().numpy()  #get the keypoints from the biggest bbox\n",
        "                all_keypoints.append(keypoints)\n",
        "            else:\n",
        "                print(f\"Warning: No bounding boxes found in frame.\")\n",
        "        else:\n",
        "            print(f\"Warning: No keypoints found in frame.\")\n",
        "\n",
        "    return all_keypoints\n",
        "\n",
        "\n",
        "def normalize_keypoints(keypoints):\n",
        "    hip_index = 11  #  index of left hip\n",
        "    shoulder_index = 5  # index of shoulder\n",
        "\n",
        "    normalized_keypoints = []\n",
        "    for frame_keypoints in keypoints:\n",
        "        if len(frame_keypoints) > max(hip_index, shoulder_index):\n",
        "            hip_point = frame_keypoints[hip_index]\n",
        "            shoulder_point = frame_keypoints[shoulder_index]\n",
        "            #  set hip point as (0,0) cordinates, set distance from hip to shoulder as 1 in every input.\n",
        "            relative_points = frame_keypoints - hip_point\n",
        "            # scaling\n",
        "            scale_factor = np.linalg.norm(shoulder_point - hip_point)\n",
        "            if scale_factor != 0:\n",
        "                relative_points /= scale_factor\n",
        "            normalized_keypoints.append(relative_points)\n",
        "        else:\n",
        "            print(f\"Warning: Frame with insufficient keypoints detected. Skipping this frame.\")\n",
        "\n",
        "    return np.array(normalized_keypoints)\n",
        "\n"
      ],
      "metadata": {
        "id": "IVazGlaIjTuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, batch_size):\n",
        "        self.x = x_set\n",
        "        self.y= 0\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "awo_2N5_jTrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"/content/drive/MyDrive/test_video.mp4\""
      ],
      "metadata": {
        "id": "P5U-X0s4jTFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "frame_buffer = deque(maxlen=35)\n",
        "swing_frames = deque(maxlen=100)\n",
        "is_recording_swing = False\n",
        "\n",
        "\n",
        "while cap.isOpened():\n",
        "  ret, frame = cap.read()\n",
        "  if not ret:\n",
        "    break\n",
        "  frame_buffer.append(frame)\n",
        "  if len(frame_buffer) == 35:\n",
        "    if not is_recording_swing:\n",
        "      keypoints = extract_keypoints(frame_buffer)\n",
        "      if len(keypoints) > 0:\n",
        "        normalized_keypoints = normalize_keypoints(keypoints)\n",
        "        #change keypoints to the numpy\n",
        "        X_array = np.array(normalized_keypoints)\n",
        "        X_array = X_array.reshape(X_array.shape[0], X_array.shape[1], -1)\n",
        "        #print(X_array.shape)\n",
        "        generator = DataGenerator(X_array, batch_size=16)\n",
        "        predictions = swing_detect_model.predict(generator)\n",
        "\n",
        "\n",
        "\n",
        "    # if is_recording_swing = True\n",
        "\n",
        "\n",
        "cap.release()\n",
        "\n"
      ],
      "metadata": {
        "id": "-kvhb4aypevd",
        "outputId": "e9e1c004-ebf6-4dab-827b-1dbb74253f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x640 1 person, 251.6ms\n",
            "Speed: 1.5ms preprocess, 251.6ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 202.7ms\n",
            "Speed: 0.0ms preprocess, 202.7ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 220.2ms\n",
            "Speed: 0.0ms preprocess, 220.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 220.4ms\n",
            "Speed: 0.1ms preprocess, 220.4ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 200.2ms\n",
            "Speed: 0.0ms preprocess, 200.2ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 204.2ms\n",
            "Speed: 0.0ms preprocess, 204.2ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 222.0ms\n",
            "Speed: 0.0ms preprocess, 222.0ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 210.7ms\n",
            "Speed: 0.0ms preprocess, 210.7ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 226.6ms\n",
            "Speed: 0.0ms preprocess, 226.6ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 202.1ms\n",
            "Speed: 0.0ms preprocess, 202.1ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 208.9ms\n",
            "Speed: 0.0ms preprocess, 208.9ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 212.2ms\n",
            "Speed: 0.0ms preprocess, 212.2ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 220.3ms\n",
            "Speed: 0.0ms preprocess, 220.3ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 198.8ms\n",
            "Speed: 0.0ms preprocess, 198.8ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 2 persons, 199.0ms\n",
            "Speed: 0.0ms preprocess, 199.0ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 216.0ms\n",
            "Speed: 0.0ms preprocess, 216.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 207.5ms\n",
            "Speed: 0.0ms preprocess, 207.5ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 210.5ms\n",
            "Speed: 0.0ms preprocess, 210.5ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 193.2ms\n",
            "Speed: 0.0ms preprocess, 193.2ms inference, 5.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 208.8ms\n",
            "Speed: 0.0ms preprocess, 208.8ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 198.9ms\n",
            "Speed: 0.0ms preprocess, 198.9ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 207.3ms\n",
            "Speed: 0.0ms preprocess, 207.3ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 200.6ms\n",
            "Speed: 0.0ms preprocess, 200.6ms inference, 3.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 202.7ms\n",
            "Speed: 0.0ms preprocess, 202.7ms inference, 5.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 220.3ms\n",
            "Speed: 0.0ms preprocess, 220.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 208.0ms\n",
            "Speed: 0.0ms preprocess, 208.0ms inference, 4.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 210.4ms\n",
            "Speed: 0.0ms preprocess, 210.4ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 204.9ms\n",
            "Speed: 0.0ms preprocess, 204.9ms inference, 4.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 220.6ms\n",
            "Speed: 0.0ms preprocess, 220.6ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 213.9ms\n",
            "Speed: 0.0ms preprocess, 213.9ms inference, 3.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 210.3ms\n",
            "Speed: 0.0ms preprocess, 210.3ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 203.3ms\n",
            "Speed: 0.0ms preprocess, 203.3ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 212.0ms\n",
            "Speed: 0.0ms preprocess, 212.0ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 201.1ms\n",
            "Speed: 0.0ms preprocess, 201.1ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "0: 640x640 1 person, 201.2ms\n",
            "Speed: 0.0ms preprocess, 201.2ms inference, 4.5ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node while/MatMul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-51-ebc6da651d9f>\", line 22, in <cell line: 7>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_rnn.py\", line 556, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 749, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 1339, in lstm_with_backend_selection\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 981, in standard_lstm\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5168, in rnn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5147, in _step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 967, in step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 2463, in dot\n\nMatrix size-incompatible: In[0]: [16,2], In[1]: [34,512]\n\t [[{{node while/MatMul}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_predict_function_8731]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a3c3b36dd7f2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print(X_array.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswing_detect_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node while/MatMul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-51-ebc6da651d9f>\", line 22, in <cell line: 7>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2655, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2440, in predict_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2425, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2413, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 2381, in predict_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_rnn.py\", line 556, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 749, in call\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 1339, in lstm_with_backend_selection\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 981, in standard_lstm\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5168, in rnn\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5147, in _step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\", line 967, in step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 2463, in dot\n\nMatrix size-incompatible: In[0]: [16,2], In[1]: [34,512]\n\t [[{{node while/MatMul}}]]\n\t [[model/lstm/PartitionedCall]] [Op:__inference_predict_function_8731]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z958vg5Ype0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EcBtHgLfpe24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNVPRF4fpe60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lCaXv7Ipe8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0JA7hxXOpe9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOj94JippfBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "auT9Os9ZpfEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcqpdT4Ipfgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z9i9CS-_pfkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_swing_start(keypoints_sequence):\n",
        "    if keypoints_sequence is not None and len(keypoints_sequence) == 35:\n",
        "        keypoints_sequence = np.array(keypoints_sequence)\n",
        "        keypoints_sequence = np.expand_dims(keypoints_sequence, axis=0)\n",
        "        prediction = swing_start_model.predict(keypoints_sequence)\n",
        "        return prediction[0][0] > 0.5  # 閾値は適宜調整してください\n",
        "    return False\n",
        "\n",
        "def classify_swing(keypoints_sequence):\n",
        "    if keypoints_sequence is not None and len(keypoints_sequence) == 30:\n",
        "        keypoints_sequence = np.array(keypoints_sequence)\n",
        "        keypoints_sequence = np.expand_dims(keypoints_sequence, axis=0)\n",
        "        prediction = swing_classification_model.predict(keypoints_sequence)\n",
        "        return np.argmax(prediction)\n",
        "    return None\n",
        "\n",
        "# 動画ファイルの読み込み\n",
        "cap = cv2.VideoCapture('path/to/your/video.mp4')\n",
        "\n",
        "frame_buffer = deque(maxlen=35)\n",
        "swing_frames = deque(maxlen=30)\n",
        "is_recording_swing = False\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    keypoints = extract_keypoints(frame)\n",
        "    normalized_keypoints = normalize_keypoints(keypoints)\n",
        "\n",
        "    if normalized_keypoints is not None:\n",
        "        frame_buffer.append(normalized_keypoints)\n",
        "\n",
        "        if len(frame_buffer) == 35:\n",
        "            if is_swing_start(list(frame_buffer)):\n",
        "                is_recording_swing = True\n",
        "                swing_frames.clear()\n",
        "                swing_frames.extend(list(frame_buffer)[-30:])  # 最後の30フレームを使用\n",
        "\n",
        "        if is_recording_swing:\n",
        "            swing_frames.append(normalized_keypoints)\n",
        "\n",
        "            if len(swing_frames) == 30:\n",
        "                swing_class = classify_swing(list(swing_frames))\n",
        "                if swing_class is not None:\n",
        "                    label = shot_types[swing_class]\n",
        "                    cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "\n",
        "                is_recording_swing = False\n",
        "\n",
        "    cv2.imshow('Swing Classification', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    # 3フレームごとにframe_bufferの先頭を削除\n",
        "    if len(frame_buffer) == 35:\n",
        "        for _ in range(3):\n",
        "            if frame_buffer:\n",
        "                frame_buffer.popleft()\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "YRXMoOWZpfzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = []\n",
        "for label, shot_type in enumerate(shot_types):\n",
        "    folder_path = f'/Users/yusuke.s/Documents/pickleball_videos/{shot_type}'\n",
        "    all_data.extend(process_video(folder_path, label))"
      ],
      "metadata": {
        "id": "QxDOG1wbhO_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}